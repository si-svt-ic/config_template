# do370

## 0 - General command

	oc login -u admin -p redhat https://api.ocp4.example.com:6443

## 1 - Setup Openshift Data Foundation (ODF)

### 1.1 - Label

	oc get node/worker01
	oc desc node worker01 => node-role.kubernetes.io/worker=
	oc get nodes -l node-role.kubernetes.io/worker=
	oc label nodes -l node-role.kubernetes.io/worker= cluster.ocs.openshift.io/openshift-storage=
	
	oc whoami --show-console
	oc debug node/worker01 -- lsblk --paths --nodeps

### 1.2 - Method 1 

Operators > OperatorHub: Local Storage
Create Local Volume Discovery 

Operators > OperatorHub: OpenShift Container Storage
Create StorageCluster
		Internal - Attached Devices
		lso-volumeset
		Stretch Cluster cleared

### 1.2 - Method 2


Install openshift local storage Operator and apply needed yaml files

	oc adm new-project openshift-local-storage
	oc project openshift-local-storage

- Local Storage Operator Group
- Subscription
- LocalVolumeDiscovery to search all logical volume(drives)
- LocalVolumeSet to create a Set of volumes 

Installing the Openshift Container Storage operator and apply needed yaml files

	oc adm new-project openshift-storage
	oc project openshift-storage

- OperatorGroup
- Subscription
- StorageCluster

### 1.3 - Validation

	oc get localvolumediscovery -n openshift-local-storage
	oc get localvolumediscoveryresults -n openshift-local-storage
	oc get localvolumeset -n openshift-local-storage

	oc get operatorgroups -n openshift-local-storage
	oc get subscriptions -n openshift-local-storage
	oc get clusterserviceversions -n openshift-local-storage


	oc get operatorgroups -n openshift-storage
	oc get subscriptions -n openshift-storage
	oc get clusterserviceversions -n openshift-storage

	oc get storagecluster -n openshift-storage
	oc get storageclasses
	
## 2 - Configuring OpenShift Cluster Services 

### 2.1 - Configuring the Internal Image Registry

Create a object storage claim (a secret is created also): noobaa-registry

	oc get secrets -l app=noobaa -n openshift-image-registry
	oc extract secret/noobaa-registry -n openshift-image-registry

Create a secret image-registry-private-configuration-user

	oc create secret generic image-registry-private-configuration-user -n openshift-image-registry \
	--from-literal=REGISTRY_STORAGE_S3_ACCESSKEY="$(cat AWS_ACCESS_KEY_ID)"  \
	--from-literal=REGISTRY_STORAGE_S3_SECRETKEY="$(cat AWS_SECRET_ACCESS_KEY)" 

Path the image registry cluster config 

	oc patch configs.imageregistry/cluster --type=merge --patch-file=imageregistry-patch.yaml
	oc get configs.imageregistry/cluster -o jsonpath='{.spec.storage}' | jq .
	oc get pods -n openshift-image-registry -l docker-registry=default

Add data to new bucket

	oc new-project services-registry
	oc new-app --name hello https://github.com/RedHatTraining/DO280-apps --context-dir hello-world-nginx
	oc logs -f buildconfig/hello

	oc apply -f job-awscli.yaml
	oc patch deployment/hello --type merge --patch '{"spec":{"template":{"spec":{"nodeSelector":{"env":"qa"}}}}}'
	oc label nodes -l env=qa env- 

### 2.2 - Configuring Monitoring

	oc exec -n openshift-monitoring statefulset/prometheus-k8s -c prometheus -- df -h /prometheus
	oc exec -n openshift-monitoring statefulset/alertmanager-main -c alertmanager -- df -h /alertmanager

Create file metrics-storage.yml

	metrics-storage.yml
	prometheusK8s:
		retention: 7d
		volumeClaimTemplate:
			spec:
				storageClassName: ocs-storagecluster-ceph-rbd
				resources:
					requests:
						storage: 40Gi
	alertmanagerMain:
		volumeClaimTemplate:
			spec:
				storageClassName: ocs-storagecluster-ceph-rbd
				resources:
					requests:
						storage: 20Gi

Create configmap name config.yaml

	oc create -n openshift-monitoring configmap cluster-monitoring-config --from-file config.yaml=metrics-storage.yml
	oc get statefulsets -n openshift-monitoring

	oc exec -n openshift-monitoring statefulset/prometheus-k8s -c prometheus -- df -h /prometheus
	oc exec -n openshift-monitoring statefulset/alertmanager-main -c alertmanager -- df -h /alertmanager

## 3 - Configuring Application Workloads

	oc get pod my-pod-name -n my-namespace -o jsonpath='{.spec.containers[*].name}'

### 3.1 - Identifying Ceph Components

Show logs pod

	oc get pods -n openshift-storage
	oc logs rook-ceph-osd-0-6cbf78cd77-t7dnr -c osd -n openshift-storage
	oc logs rook-ceph-mon-0-6cbf78cd77-t7dnr -c mon -n openshift-storage
	
Obtain the cluster health

	oc exec -it pod/rook-ceph-operator-548bcdc79f-xcgjb -c rook-ceph-operator -n openshift-storage  -- /bin/bash
	bash-4.4$ ceph -c /var/lib/rook/openshift-storage/openshift-storage.config health
	bash-4.4$ ceph -c /var/lib/rook/openshift-storage/openshift-storage.config -s
	bash-4.4$ ceph -c /var/lib/rook/openshift-storage/openshift-storage.config df

Obtain the cluster logs bundle

	oc adm must-gather --image=registry.redhat.io/ocs4/ocs-must-gather-rhel8:v4.7 --dest-dir=must-gather

### 3.2 - Configuring Applications to use File Storage

Show route

	oc get route/image-tool-pvc -o jsonpath='{.spec.host}'

File pvc.yaml



File deployment.yaml
	


Create app image-tool

	oc apply -f pvc.yaml -f deployment.yaml
	oc exec -it deployment/image-tool-pvc -- df -h /var/storage
	oc logs deployment/image-tool-pvc 
	
Create app nginx and verify 2 app have same pvc

	oc get pods -l app=image-tool
	oc get pods -l app=nginx

### 3.3 - Configuring Applications to use Block Storage

Project workloads-block
	
	oc new-project workloads-block

File pvc.yaml

	---
	apiVersion: v1
	kind: PersistentVolumeClaim
	metadata:
		name: famous-quotes-db
	spec:
		accessModes:
		- ReadWriteOnce
		storageClassName: ocs-storagecluster-ceph-rbd
		resources:
			requests:
				storage: 1Gi

	oc apply -f ~/DO370/labs/workloads-block/pvc.yaml
	oc process mariadb-persistent -n openshift \
-p DATABASE_SERVICE_NAME=famous-quotes-db \
-p MYSQL_USER=myuser -p MYSQL_PASSWORD=r3dh4t \
-p MYSQL_DATABASE=quotes \
| oc create -f -

## 4 - Managing 

	oc get pod my-pod-name -n my-namespace -o jsonpath='{.spec.containers[*].name}'

### 4.1 - Quota

Create Developer user and add rule create pvc

	oc adm policy add-role-to-user basic-user developer -n capacity-quotas
	oc adm policy who-can create persistentvolumeclaims
	admin
	system:admin
	oc adm policy add-cluster-role-to-user cluster-admin developer
	oc adm policy who-can create persistentvolumeclaims
	admin
	developer <<<<<
	system:admin


	pvc-quota.yaml 
	apiVersion: v1
	kind: ResourceQuota
	metadata:
		name: pvc-quota
	spec:
		hard:
			persistentvolumeclaims: "1"

	oc get ResourceQuotas
	oc login -u developer -p developer https://api.ocp4.example.com:6443
  oc apply -f pvc-test1.yaml
	oc get ResourceQuotas
	oc apply -f pvc-test1.yaml


### 4.2 - Expand pvc

	oc patch pvc/pg-capacity-extend-ge -p '{"spec":{"resources":{"requests": {"storage": "150M"}}}}'
	oc edit pvc/pg-capacity-extend-ge
	oc rollout latest dc/pg-capacity-extend-ge

### 4.3 - Expand hard drive

	oc get pods -n openshift-storage -l app=rook-ceph-osd
	oc get localvolumediscoveryresults -n openshift-local-storage
	oc describe localvolumediscoveryresult/discovery-result-worker01 -n openshift-local-storage


## 5 - Backup Restore

The configuration map contains the following parameters:

### 5.1 - Backup & Restore

Create Developer user and add rule create pvc

### 5.2 - Volume Snapshot & Clone

Create Developer user and add rule create pvc

## 6 - ODF Object Storage 

The configuration map contains the following parameters:
• BUCKET_HOST
• BUCKET_PORT
• BUCKET_NAME
• BUCKET_REGION
• BUCKET_SUBREGION
The secret contains the keys required to access the bucket.
• AWS_ACCESS_KEY_ID
• AWS_SECRET_ACCESS_KEY
Object Route
	External Route for incoming request: 
		NooBaa Object: route/s3
		Openshift-Storage: route/ocs-storageclustercephobjectstore

	oc get pod my-pod-name -n my-namespace -o jsonpath='{.spec.containers[*].name}'

### 6.1 - S3

Create Developer user and add rule create pvc

	oc exec -it deployment/s3-cli -n object-define -- /bin/bash
	aws s3 ls s3://
	object-bucket-8e722bfb-f687-4fa3-820a-bd1ffff08084
	printenv BUCKET_NAME
	object-bucket-8e722bfb-f687-4fa3-820a-bd1ffff08084

	aws s3 ls s3://${BUCKET_NAME} --summarize
	aws s3 cp sample-file.txt s3://${BUCKET_NAME}/
	aws s3 cp s3://${BUCKET_NAME}/sample-file.txt /tmp/
	aws s3 cp sample-file.txt s3://${BUCKET_NAME}/sample-file.txt
	aws s3 cp s3://${BUCKET_NAME}/sample-file.txt s3://${BUCKET_NAME}/second-file.txt
	aws s3 cp s3://${BUCKET_NAME}/second-file.txt /tmp/
	aws s3 ls s3://${BUCKET_NAME} --summarize

Create prefix

	aws s3api put-object --bucket ${BUCKET_NAME} --key prefix
	aws s3 mv s3://${BUCKET_NAME}/prefix s3://${BUCKET_NAME}/my-s3-prefix
	aws s3 ls s3://${BUCKET_NAME}
	aws s3 mv s3://${BUCKET_NAME}/second-file.txt s3://${BUCKET_NAME}/other-file.txt
	aws s3 mv s3://${BUCKET_NAME}/sample-file.txt s3://${BUCKET_NAME}/my-s3-prefix/
	aws s3 ls s3://${BUCKET_NAME} --recursive --summarize

Sync file in folder

	aws s3api put-object --bucket ${BUCKET_NAME} --key icons
	aws s3 sync /usr/share/httpd/icons/ s3://${BUCKET_NAME}/icons/
	aws s3 ls s3://${BUCKET_NAME} --recursive --human-readable --summarize

Delete

	aws s3 rm s3://${BUCKET_NAME}/other-file.txt
	aws s3 rm s3://${BUCKET_NAME}/icons/small/ --recursive

### 6.2 - Client access Object Storage Claim

Create:
• Object Bucket Claim Name: my-object-bucket-claim
• Storage Class: openshift-storage.noobaa.io
• Bucket Class noobaa-default-bucket-class

	oc get route/s3 -n openshift-storage -o jsonpath='{.spec.host}{"\n"}' 
		s3-openshift-storage.apps.ocp4.example.com
	oc extract configmap/my-object-bucket-claim --to=-
	
	export BUCKET_HOST="s3-openshift-storage.apps.ocp4.example.com"
	export BUCKET_NAME="my-object-bucket-claim-27f4ce2f-13ca-44cc-b8a5-1a747989cfb3"
	export AWS_CA_BUNDLE=/etc/pki/tls/certs/ca-bundle.crt

	aws configure
	cat ~/.aws/credentials
	aws s3 ls s3:// --endpoint-url "https://${BUCKET_HOST}"

Config default S3 endpoint

	pip install awscli-plugin-endpoint
	aws configure set plugins.endpoint awscli_plugin_endpoint
	aws configure --profile default set s3.endpoint_url https://${BUCKET_HOST}
	cat ~/.aws/config
		[default]
		region = us-east-1
		s3 =
		endpoint_url = https://s3-openshift-storage.apps.ocp4.example.com
		[plugins]
		endpoint = awscli_plugin_endpoint

	aws s3 ls s3://
	aws s3 ls s3://${BUCKET_NAME} --summarize

### 6.2 - Application access Object Storage Claim

	oc apply -f serviceaccount.yaml -f deployment.yaml -f service.yaml -f route.yaml
	Edit the deployment.yaml
	oc apply -f obc.yaml -f deployment-obc.yaml

### 6.3 - Monitoring

Monitoring > Metrics
	• rate(NooBaa_providers_bandwidth_read_size[2m])
	• rate(NooBaa_providers_bandwidth_write_size[2m])